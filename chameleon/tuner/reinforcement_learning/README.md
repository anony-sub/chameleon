# Implementation of Proximal Policy Optimization (PPO) #

PPO Paper: https://arxiv.org/pdf/1707.06347.pdf <br/>

__NOTE__

Focus of this paper was to enhance the usability of the PPO, making it more portable. <br/>
Internal implementation is from another repo, and the idea about the architecture is from TensorForce. <br/>

PPO Implementation: https://github.com/uidilr/ppo_tf <br/>

__TODO__

1. Recurrent network support <br/>
2. Fix names <br/>
